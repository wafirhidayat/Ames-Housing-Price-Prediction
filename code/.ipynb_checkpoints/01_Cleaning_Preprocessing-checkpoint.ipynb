{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d278143d-0852-407f-a9a8-f228092ff95b",
   "metadata": {},
   "source": [
    "# Project 2: Ames Housing Data and Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a8485-41b4-494b-a32e-0c3974d0941e",
   "metadata": {},
   "source": [
    "**Project Statement:** This project aims to examine see what factors contribute in predicting property prices in the housing market using the Ames Housing Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f11ec-b7cd-44c3-993d-cc66f4665c17",
   "metadata": {},
   "source": [
    "**Summary:** The Ames Housing Dataset is an exceptionally detailed and robust dataset with a total number of 80 different features relating to houses and over 2000 observations. There are many factors involved in real estate pricing. In reality, it is often hard for us to tell which factors are more important and which factors are not. For this project, we will attempt to build a prediction model to predict house prices of Ames, Iowa with supervised predictive modeling techniques. The dataset is from a Kaggle competition [(link)](https://www.kaggle.com/competitions/dsi-us-11-project-2-regression-challenge/overview).\n",
    "\n",
    "We will construct multiple regression model that will take in several independent variables, predict the sale price of a house. We will then train the models based on the training dataset and validate the model through the validation dataset. Finally, our goal is to best predict the sale prices of the houses in the test set, and our predictions will then be evaluated on Kaggle. From there, we will find out which factors contribute the most in predicting property prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a7c88-ef72-46ce-818a-6b850dc4b997",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [Cleaning Train Dataset](#Cleaning-Dataset)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Preprocessing](#Preprocessing)\n",
    "- [Cleaning and Preprocessing Test and Validation Dataset](#Cleaning-and-Preprocessing-Test-and-Validation-Dataset)\n",
    "- [Final Check](#Final-Check)\n",
    "- [Data Export](#Data-Exporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395157f-1c0c-45c5-bf09-7ac89e7fee7f",
   "metadata": {},
   "source": [
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705027d-71fa-41c8-9087-8c19ff28a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75562e-2171-4490-ae65-aaade9d01015",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae84531-c0d8-4285-9b0d-cc78d701a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data importing for train dataset\n",
    "train_df = pd.read_csv('./datasets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7e199-0a49-4f12-b241-0d0437ed49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151745f-1c66-4aa3-896b-a9b60fb84f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure jupyter lab to prevent truncation for easier reference for columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498f9fa-6445-4956-9db6-7c7a02d6c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning column names \n",
    "train_df.rename(columns=lambda x: x.lower().replace(' ', '_').replace('/', '_'), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d3360-d830-4e27-a236-ae3746341ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f6955-b580-495a-be2c-92097b5d19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training dataset into train and validation dataset\n",
    "train, valid = train_test_split(train_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3592eb0-b7bb-4150-8cb0-ce112b6cb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting index for shuffled training & validation sets\n",
    "# Reassigning instead of inplace parameter used to avoid SettingWithCopy warning\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4263c8-5ad4-4990-8a85-89c248b2075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting training & validation set to .csv files\n",
    "train.to_csv('./datasets/partial_train.csv', index=False)\n",
    "valid.to_csv('./datasets/valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb92c6-25fe-4489-9bbe-2d5ddd8c3e8f",
   "metadata": {},
   "source": [
    "After importing the train dataset which our model will be based on, we split the dataset into two namely one for training of the model and second for validating the model. We named it 'train' and 'valid' datasets to avoid confusion with the test dataset which our prediction will be based on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a71a8-d174-4463-a9a3-9f9af2f0514e",
   "metadata": {},
   "source": [
    "### Handling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff104af6-c859-4c22-a2b1-4f65153c605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making function to replace null values \n",
    "def change_values(df,feat_list, obj_replace_with, else_replace_with):\n",
    "    for col in df[feat_list]:\n",
    "        if df[col].dtype == object:\n",
    "            x=df[col].fillna(obj_replace_with, inplace=True)\n",
    "        else:\n",
    "            x=df[col].fillna(value=else_replace_with, inplace=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd935c79-ba07-4c24-8dd2-512b17e14bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "train.select_dtypes(include=['int64']).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb1702-dd75-44a4-becc-b20bcb1b716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls in columns with float values\n",
    "train.select_dtypes(include=['float']).isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5559e3-818a-4895-9b6f-268b38b53ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls in columns with float values\n",
    "train.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae451c2-53f3-43ed-8a2b-b7b27bd82960",
   "metadata": {},
   "source": [
    "#### Features with Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7988f33-e665-4ed7-9de6-eb9e95d9dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling garage\n",
    "##checking 'garage_age'\n",
    "train.loc[\n",
    "    np.abs(train['garage_yr_blt'] - train['year_built']) <= 1,\n",
    "    ['garage_yr_blt', 'year_built']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e1e6e-902b-4f40-8fa8-d2c979d5c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with values from year_built column\n",
    "train.loc[train['garage_yr_blt'].isnull(), ['garage_yr_blt']] = train.loc[train['garage_yr_blt'].isnull(), 'year_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc863e57-de72-4e1a-aeae-f5631171f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##handling years\n",
    "\n",
    "#combining features to create new features\n",
    "train['property_age'] = train['yr_sold'] - train['year_built']\n",
    "train['garage_age'] = train['yr_sold'] - train['garage_yr_blt']\n",
    "train['age_remod_add'] = train['year_remod_add'] - train['year_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bc1c5-043e-428d-a1ec-11cca33622d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns after making new features\n",
    "train.drop(columns=['yr_sold','year_built','garage_yr_blt','year_remod_add'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6c3d2-1719-4807-9d5b-8e6ed99c0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers\n",
    "train[['garage_age']].sort_values(by=['garage_age'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb23dc1-c785-4f42-abd4-78c6cb48188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[train['garage_age'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff06e7a-a56b-4d33-a5fa-6b36a5efdee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab1901-f60d-40cd-a457-6951f428e0b7",
   "metadata": {},
   "source": [
    "Having to know when or the year that the property was built does not value add to the model. However, age of the respective features may contribute better. New columns were built to reflect this and the years features were dropped subsequently.\n",
    "\n",
    "Garage features were cleaned up with `'garage_yr_blt'` missing values being replaced with the same values as what was found in their `'year_built'`. Also, '`garage_cars'`,`'garage_area'` were also inputted with 0 value since they reflect an absence of garage and falls in the same row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643da74f-c95d-4f44-83ef-59e6e1720952",
   "metadata": {},
   "source": [
    "#### Basement Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442fe2b-90f1-4cde-beaf-2e94bda3f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##making function that will output a list of same named features\n",
    "col_list = train.columns.values.tolist()\n",
    "\n",
    "def making_list (column, substr):\n",
    "    make_list=[]\n",
    "    for col in column:\n",
    "        if substr in col:\n",
    "            make_list.append(col)\n",
    "    return make_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d7807-7234-4a5e-a51a-2390113ae112",
   "metadata": {},
   "outputs": [],
   "source": [
    "##basement check\n",
    "bsmt_list= making_list(col_list,'bsmt')\n",
    "train[bsmt_list].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b46ff0-b6bd-41e2-ab86-75c422746b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[bsmt_list].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de835004-83db-42c3-aec2-1d90252076f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('bsmtfin_type_2')['bsmt_exposure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263f5a2-ec1c-45c3-8401-ff463fcb131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('bsmt_exposure')['bsmtfin_type_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8cd21-9ed1-48f9-a0e2-310c5fdc47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing 'bsmtfin_type_2' and 'bsmt_exposure' to mode\n",
    "change_values(train,['bsmtfin_type_2'], 'Unf', 0.0)\n",
    "\n",
    "change_values(train,['bsmt_exposure'], 'No', 0.0)\n",
    "\n",
    "#changing balance basement features to appropriate values\n",
    "change_values(train, bsmt_list, 'NA', 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78aa776-3140-4cfd-9ed3-6569c8508c25",
   "metadata": {},
   "source": [
    "For the basement features, there appears to be two cases: missing entries where there is no basement, and missing values where there is a basement. Firstly, we identified the columns with some missing values even though there was a presence of a basement. For this case, we input the most occurring value in relation to each other. After that, we replaced the missing values with `'NA'` for datatype object after seeing the data dictionary that these features show that missing value represent the absence of the feature and 0 for datatype float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f24332-afe0-4214-98ee-a316d097d948",
   "metadata": {},
   "source": [
    "#### Features with 'NA' as a Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9284c0f-5280-4f14-b30f-f71038c9803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to confirm that NA values are actually the missing values\n",
    "train['alley'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ea2a4-98c1-49c3-ac6e-2050bc763d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to confirm that NA values are actually the missing values\n",
    "train_df['fence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7cca9-1cb9-4af8-aa9e-783044d3527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if all null values means absence of feature that has no null values\n",
    "def check_missing(area, feat):\n",
    "    return print(train.loc[train[area] > 0, [feat]].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587e202-40ef-494e-baa5-97b18a5fb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check against features with 'object' datatype\n",
    "check_missing('garage_area', 'garage_qual')\n",
    "check_missing('garage_area', 'garage_type')\n",
    "check_missing('fireplaces', 'fireplace_qu')\n",
    "check_missing('mas_vnr_area', 'mas_vnr_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36000e2-52cb-4590-a914-363b3042b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN values in columns with object datatypes as 'NA' and those in float to value of 0\n",
    "float_list = train.select_dtypes(include=['float64']).isnull().columns.tolist()\n",
    "obj_list = train.select_dtypes(include=['object']).isnull().columns.tolist()\n",
    "\n",
    "train[obj_list]=train[obj_list].fillna('NA')\n",
    "train[float_list]=train[float_list].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c512a54-5e3a-4bec-aa55-ac95e6464b5b",
   "metadata": {},
   "source": [
    "These are features that have 'NA' as one of the values for the features that will indicate an absence of the feature. After cross-checking with features that describe the same thing (eg `'garage_qual'` would be related to `'garage_area'` as it explains garage features) that has no missing values, we can conclude that the missing values are indeed the case of an absence of the feature in the property. These missing values were then imputed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e879a19-b15d-4a80-8ac2-f972b30ac922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for any missed out missing values\n",
    "train.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a6b5c-2aa6-4c8e-9891-4748cacb9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ba32d-e906-4059-9087-1a67fca79710",
   "metadata": {},
   "source": [
    "### Feature Classification\n",
    "\n",
    "Features will be divided to four categories:\n",
    "\n",
    "- Ordinal\n",
    "- Nominal\n",
    "- Continuous\n",
    "- Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbd4b1-05f5-4460-8d38-ceacf5aeccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of columns\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808c065-0586-4422-961d-b7426fe6448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary of categorised features\n",
    "feature_cat = {\n",
    "    'ordinal_feat':['lot_shape','utilities','land_slope','overall_qual','overall_cond','exter_qual','exter_cond','bsmt_qual','bsmt_cond',\n",
    "                    'bsmt_exposure','bsmtfin_type_1', 'bsmtfin_type_2','heating_qc','electrical','kitchen_qual','functional','fireplace_qu',\n",
    "                    'garage_finish','garage_qual','garage_cond','paved_drive','pool_qc','fence'],\n",
    "    'continuous_feat':['lot_frontage','lot_area','mas_vnr_area','bsmtfin_sf_1','bsmtfin_sf_2','bsmt_unf_sf',\n",
    "                    'total_bsmt_sf','1st_flr_sf','2nd_flr_sf','low_qual_fin_sf','gr_liv_area','garage_area',\n",
    "                      'wood_deck_sf','open_porch_sf','enclosed_porch','3ssn_porch','screen_porch','pool_area','misc_val',\n",
    "                     'property_age','garage_age','age_remod_add','saleprice'],\n",
    "    'nominal_feat':['ms_subclass','ms_zoning','street','alley','land_contour','lot_config','neighborhood','condition_1','condition_2',\n",
    "                    'bldg_type','house_style','roof_style','roof_matl','exterior_1st','exterior_2nd','mas_vnr_type',\n",
    "                  'foundation','heating','central_air','garage_type','misc_feature','sale_type','mo_sold'],\n",
    "    'discrete_feat':['id','pid','bsmt_full_bath','bsmt_half_bath','full_bath','half_bath','bedroom_abvgr','kitchen_abvgr','totrms_abvgrd',\n",
    "                   'fireplaces','garage_cars']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea2fec-f74f-47cf-ab52-c9e142561668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for total features in the dictionary to check for any missed out features\n",
    "sum((len(val) for val in feature_cat.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f617f-d482-46c5-ac2b-b428c3232313",
   "metadata": {},
   "source": [
    "Based on the data dictionary on Kaggle, the features are classified into the respective categories. The age of features that were created were placed in `'continuous_feat'`. In total, there are 80 unique features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9ed6a-1c9f-4576-89a3-9b7e73c51670",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b767335-0457-458d-a285-e9943087f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to show a boxplot and barplot for each feature side by side\n",
    "def subplot_box_hist(dataframe, list_of_features, figsize=()):\n",
    "    nrows = len(list_of_features) # 1 row per feature, 2 plots per feature\n",
    "    fsize = (14, len(list_of_features) * 5)\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize=fsize, sharex=False, sharey=False)\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    \n",
    "    for i, feature in enumerate(list_of_features):\n",
    "        # boxplot on the left\n",
    "        sns.boxplot(\n",
    "            ax=ax[i*2],\n",
    "            data=dataframe,\n",
    "            x=feature,\n",
    "            y='saleprice',\n",
    "            orient='v',\n",
    "            linewidth=1,\n",
    "            palette='viridis'\n",
    "        )\n",
    "        \n",
    "        # bar chart on the right (histplot used to reflect proportion)\n",
    "        if dataframe[feature].dtype == object:\n",
    "            sns.histplot(\n",
    "                data=dataframe,\n",
    "                x=feature,\n",
    "                ax=ax[(i*2 + 1)],\n",
    "                hue=feature,\n",
    "                stat='probability',\n",
    "                palette='viridis',\n",
    "                legend=False,\n",
    "                bins=6\n",
    "            \n",
    "            )\n",
    "        else: # To avoid overlapping values in the same bin for numerical features\n",
    "            sns.histplot(\n",
    "                data=dataframe,\n",
    "                x=feature,\n",
    "                ax=ax[(i*2 + 1)],\n",
    "                hue=feature,\n",
    "                stat='probability',\n",
    "                palette='viridis',\n",
    "                legend=False,\n",
    "                discrete=True,\n",
    "                bins=50\n",
    "                \n",
    "            )\n",
    "\n",
    "        ax[i*2].set_xlabel(feature.replace('_', ' ').title(), fontsize=14, fontweight='bold')\n",
    "        ax[(i*2) + 1].set_xlabel(feature.replace('_', ' ').title(), fontsize=14, fontweight='bold')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354732a5-5283-41e5-ae8e-4a39ec0b5cef",
   "metadata": {},
   "source": [
    "### Ordinal Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fcb24-2577-4ab6-b54e-11e3937e82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check ordinal features\n",
    "subplot_box_hist(train, feature_cat.get('ordinal_feat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1508d8-ebc3-4d88-9c8d-570249199157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# garage columns seem peculiar, checking further\n",
    "(train['garage_qual'] == train['garage_cond']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8643d7-b58b-48ee-b05b-02a8bd54ee1f",
   "metadata": {},
   "source": [
    "For ordinal features, those with extreme skews were dropped, such as `'pool_qc'`. In addition, the histograms reveal that some features that have the same description such as garage and basement, based on quality and condition, seem to have a similar response/shape. They will be potentially be either be dropped or combined to prevent a multi-collinearity in our model.\n",
    "As for `'garage_qual'` and `'garage_cond'`, it has 90% of the values to be the same and one will be dropped.\n",
    "\n",
    "Ordinal features dropped:\n",
    "\n",
    "1) `'fence'`\n",
    "2) `'pool_qc'`\n",
    "3) `'paved_drive'`\n",
    "4) `'functional'`\n",
    "5) `'land_slope'`\n",
    "6) `'utilities'`\n",
    "7) `'garage_qual'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91777da8-8df2-422a-a45e-f014ede63866",
   "metadata": {},
   "outputs": [],
   "source": [
    "##making function to drop columns and update feature dictionary\n",
    "def drop_feature(df,feature_name,list_of_dropped_features):\n",
    "    df.drop(columns=list_of_dropped_features, inplace=True)\n",
    "    \n",
    "    for feat in list_of_dropped_features:\n",
    "        feature_cat[feature_name].remove(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1669fb5-92bf-40dc-b219-ce8accbf3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping ordinal features\n",
    "dropped_ordinal_feat = ['fence','pool_qc','paved_drive','functional','land_slope','utilities', 'garage_qual']\n",
    "\n",
    "drop_feature(train,'ordinal_feat',dropped_ordinal_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc714f-ab05-4c77-96a6-030f3e22aa54",
   "metadata": {},
   "source": [
    "### Nominal Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b9736-8101-43a2-894b-2bae7435fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nominal features\n",
    "subplot_box_hist(train, feature_cat.get('nominal_feat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad17b47-be2f-4fc3-ae1c-6529734f1060",
   "metadata": {},
   "source": [
    "For the nominal features, those with extreme skew in values in their histograms, such as `'alley'` will be dropped as it will not help with the modelling. \n",
    "For those with high skew, those with no trend with the `'saleprice'` in the corresponding boxplot was dropped as well. Therefore, some like `'sale_type'` were retained as the boxplot looks to have some form of trend that may contribute to the model.\n",
    "Next, the boxplots were examined and those with IQRs that have high overlapping were also dropped, for example `'misc_feature'`.  \n",
    "\n",
    "Nominal features dropped:\n",
    "\n",
    "1) `'misc_feature'`\n",
    "2)  `'heating'`\n",
    "3) `'roof_matl'`\n",
    "4) `'condition_1'`\n",
    "5) `'condition_2'`\n",
    "6) `'alley'`\n",
    "7) `'street'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9b87a-128b-4646-9a1f-c1311b5a21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping nominal features\n",
    "dropped_nominal_feat = ['misc_feature','heating','roof_matl','condition_1','condition_2','alley','street']\n",
    "\n",
    "drop_feature(train,'nominal_feat',dropped_nominal_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4f265-73cf-4565-bd10-943d957d00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing int in ms_subclass to str as they represent a class of building\n",
    "train['ms_subclass'] = train['ms_subclass'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbdc32-e838-4a02-ad8b-c11c0310624c",
   "metadata": {},
   "source": [
    "### Continuous Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741e4d7-a68b-4d8e-b05b-4b5de2a94b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check continous data\n",
    "\n",
    "# Creating a function to show scatter plots of feature against sale price\n",
    "def subplot_scatter(dataframe, list_of_features, figsize=()):\n",
    "    nrows = int(np.ceil(len(list_of_features)/2))\n",
    "    fsize = (14, nrows * 5)\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize=fsize, sharex=False, sharey=True)\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    for i, feature in enumerate(list_of_features):      \n",
    "        sns.regplot(\n",
    "            data=dataframe,\n",
    "            x=feature, \n",
    "            y='saleprice', \n",
    "            ax=ax[i],\n",
    "            scatter_kws={'s': 4, 'alpha': 0.5},\n",
    "            line_kws={'color':'lightcoral'}\n",
    "        )\n",
    "\n",
    "        ax[i].set_xlabel(feature.replace('_', ' ').title(), fontsize=14, fontweight='bold')\n",
    "        ax[i].title.set_text(f'Scatterplot of {feature.replace(\"_\" , \" \").title()}')\n",
    "         \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c3182-6bda-475d-aa32-057ea66381c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_scatter(train, feature_cat['continuous_feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2819bb2-da06-47c8-b482-c32cc708855a",
   "metadata": {},
   "source": [
    "For continuous features, features that have extremely high percentage of values plotted at 0 would not contribute much to the model. Therefore, they will be dropped.\n",
    "\n",
    "Continuous features dropped:\n",
    "1) `'misc_val'`\n",
    "2) `'pool_area'`\n",
    "3) `'3ssn_porch'`\n",
    "4) `'low_qual_fin_sf'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c362f-da9c-4cb4-945c-112320060643",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_continuous_feat = ['misc_val','pool_area','3ssn_porch','low_qual_fin_sf']\n",
    "\n",
    "drop_feature(train,'continuous_feat',dropped_continuous_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ea129-c877-4d0d-9585-165fb75708cb",
   "metadata": {},
   "source": [
    "### Discrete Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea67ef8-4542-48d4-933a-d112b39ed500",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_discrete = train[feature_cat.get('discrete_feat')].corrwith(train[['saleprice']])\n",
    "\n",
    "matrix = np.triu(corr_discrete)\n",
    "\n",
    "plt.figure(figsize = (15,12))\n",
    "sns.heatmap(train_df[corr_discrete.index].corr(), annot=True, mask=matrix)\n",
    "plt.title('Correlation Between Discrete Features and Salesprice', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd123c3-90fe-40d7-a640-4620716c296e",
   "metadata": {},
   "source": [
    "For discrete features, features that have less than 0.20 correlation with `'saleprice'` will be dropped. There are also features that cannot be used as they act as identifiers, namely '`id'` and `'pid'` that will be dropped. \n",
    "Basement features will not be dropped yet to check if combining some will help the model.\n",
    "\n",
    "Discrete features dropped:\n",
    "1) `'id'`\n",
    "2) `'pid'`\n",
    "3) `'kitchen_abvgr'`\n",
    "4) `'bedroom_abvgr'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08a6d4-116d-4274-b3dc-17a27d047744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping discrete features\n",
    "dropped_discrete_feat = ['id','pid','kitchen_abvgr','bedroom_abvgr']\n",
    "\n",
    "drop_feature(train,'discrete_feat',dropped_discrete_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348fd73-cacd-42c9-901e-44e5d2f2540e",
   "metadata": {},
   "source": [
    "### Additional Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e3c31-0613-4e94-bea9-980b43afc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,12))\n",
    "correlation = train.select_dtypes(exclude=['object']).corr()\n",
    "sns.heatmap(correlation, mask = correlation <0.8, linewidth=0.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30eec3b-afde-477f-9f29-f238c465c644",
   "metadata": {},
   "source": [
    "From the above correlation matrix, we have pinpointed certain features that are highly correlated:\n",
    "\n",
    "- `'fireplaces'` and `'fireplace_qual'`\n",
    "- `'garage_area'` and `'garage_cars'`\n",
    "- `'garage_age'` and `'property_age'`\n",
    "\n",
    "Therefore, to avoid multi-collinearity, one of the features in the pairs will be dropped based on discretion. Since `'garage_age'` was created from the same feature in creation of `'property_age'`, there is bound to have collinearity. Furthermore, about 75% of the garages were built in the same year as the year the property was built.\n",
    "\n",
    "Features to drop:\n",
    "1) `'fireplaces'`\n",
    "2) `'garage_cars'`\n",
    "3) `'garage_age'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cadef5-8dfd-4a20-835c-2c273b5d5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping additional features\n",
    "dropped_add_feat = ['fireplaces','garage_cars','garage_age']\n",
    "\n",
    "##updating dictionary\n",
    "for item in feature_cat.values():\n",
    "    for feature in dropped_add_feat:\n",
    "        if feature in item:\n",
    "            item.remove(feature)\n",
    "\n",
    "##dropping from train dataframe\n",
    "train.drop(columns=dropped_add_feat, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c736ff5e-0b6b-459c-a475-94ac5552c27d",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b774934-1a4b-455b-a527-586f6aad5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = train.columns.values.tolist()\n",
    "\n",
    "area_list = making_list(col_list, 'area')\n",
    "sf_list = making_list(col_list, '_sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8793ef-4365-4b10-ae17-d5f7719fedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_feats = train[area_list + sf_list + ['saleprice']].corr()\n",
    "\n",
    "matrix = np.triu(corr_feats)\n",
    "\n",
    "plt.figure(figsize = (15,12))\n",
    "sns.heatmap(train_df[corr_feats.index].corr(), annot=True, mask=matrix)\n",
    "plt.title('Correlation Between Size-Related Features', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954fcd6-551c-481e-9963-0995d5f19238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating interaction features for feature pairs with absolute correlation value > 0.5\n",
    "train['1st_flr_sf_total_bsmt_sf'] = train['1st_flr_sf'] * train['total_bsmt_sf']\n",
    "train['bsmtfin_sf_1_total_bsmt_sf'] = train['bsmtfin_sf_1'] * train['total_bsmt_sf']\n",
    "train['gr_liv_area_2nd_flr_sf'] = train['gr_liv_area'] * train['2nd_flr_sf']\n",
    "train['gr_liv_area_1st_flr_sf'] = train['gr_liv_area'] * train['1st_flr_sf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eae724-f265-4ee1-8f13-b4c690f93210",
   "metadata": {},
   "source": [
    "Based on the heamap, not many of the features related to size were highly correlated to each other. Even for the features with extremely high correlation values such as `'1st_flr_sf'` and `'total_bsmt_sf'`, we will not be dropping them as they are deemed too important (judging from their high correlation value with '`saleprice'`).\n",
    "\n",
    "However, we can still create interaction features for the feature pairs with significant correlation values, to see if these new features have a bigger effect on the model later on. As such new features were created from the above combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f725e6-facc-4703-899c-998b256947ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating dictionary\n",
    "new_cont_feat = ['1st_flr_sf_total_bsmt_sf', 'bsmtfin_sf_1_total_bsmt_sf', 'gr_liv_area_2nd_flr_sf', 'gr_liv_area_1st_flr_sf']\n",
    "\n",
    "feature_cat.get('continuous_feat').extend(new_cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390ffe8-f582-410b-a697-e85a9305869b",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4487043-85ee-478d-89e6-d144769c6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking outliers\n",
    "train[['gr_liv_area']].sort_values(by=['gr_liv_area'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee41aab-1fbc-481a-89ce-9d0b1b9f135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['total_bsmt_sf']].sort_values(by=['total_bsmt_sf'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aecfb49-f99b-4a5b-98f5-70d0a9a69efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['1st_flr_sf']].sort_values(by=['1st_flr_sf'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8e607-db46-418a-abd2-5d4af274e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out the outliers\n",
    "train = train.loc[train['gr_liv_area'] < 4500]\n",
    "train = train.loc[train['total_bsmt_sf'] < 6000]\n",
    "train = train.loc[train['1st_flr_sf'] < 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7bfcb8-74cc-4427-9f63-61b6f121c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea034bfe-70bb-4c5d-a2fc-68c895d0e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3b807-02a4-4628-b2dd-6e1954b5713b",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6370ca2-7d43-4967-9877-eb0baeb69735",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb3200-8405-4666-9a41-ff5a3b25315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols_mapping = [{\n",
    "    'col':'lot_shape',\n",
    "    'mapping': {\n",
    "        'IR3': 0,\n",
    "        'IR2': 1,\n",
    "        'IR1': 2,\n",
    "        'Reg': 3\n",
    "    }}, {   \n",
    "     'col': 'exter_qual',\n",
    "    'mapping': {\n",
    "        'Ex': 4,\n",
    "        'Gd':3, \n",
    "        'TA':2,\n",
    "        'Fa':1,\n",
    "        'Po':0,\n",
    "    }}, {\n",
    "    'col': 'exter_cond',\n",
    "    'mapping': {\n",
    "        'Ex': 4,\n",
    "        'Gd':3, \n",
    "        'TA':2,\n",
    "        'Fa':1,\n",
    "        'Po':0,\n",
    "    }}, {      \n",
    "        'col': 'bsmt_qual',\n",
    "    \"mapping\": {\n",
    "        'Ex': 4,\n",
    "        'Gd':3, \n",
    "        'TA':2,\n",
    "        'Fa':1,\n",
    "        'Po':0,\n",
    "        'NA':-1,\n",
    "    }}, {\n",
    "    'col': 'bsmt_cond',\n",
    "    'mapping': {\n",
    "        'Ex': 4,\n",
    "        'Gd':3, \n",
    "        'TA':2,\n",
    "        'Fa':1,\n",
    "        'Po':0,\n",
    "        'NA':-1,\n",
    "    }}, {\n",
    "    'col':'bsmt_exposure',\n",
    "    'mapping': {\n",
    "        'NA': -1,\n",
    "        'No': 0,\n",
    "        'Mn': 1,\n",
    "        'Av': 2,\n",
    "        'Gd': 3,\n",
    "    }}, {\n",
    "    'col':'bsmtfin_type_1',\n",
    "    'mapping': {\n",
    "        'NA': -1,\n",
    "        'Unf': 0,\n",
    "        'LwQ': 1,\n",
    "        'Rec': 2,\n",
    "        'BLQ': 3,\n",
    "        'ALQ': 4,\n",
    "        'GLQ': 5\n",
    "    }}, {\n",
    "    'col':'bsmtfin_type_2',\n",
    "    'mapping': {\n",
    "        'NA': -1,\n",
    "        'Unf': 0,\n",
    "        'LwQ': 1,\n",
    "        'Rec': 2,\n",
    "        'BLQ': 3,\n",
    "        'ALQ': 4,\n",
    "        'GLQ': 5,\n",
    "    }}, {\n",
    "    'col': 'heating_qc',\n",
    "    'mapping': {\n",
    "        'NA': -1,\n",
    "        'Po': 0,\n",
    "        'Fa': 1,\n",
    "        'TA': 2,\n",
    "        'Gd': 3, \n",
    "        'Ex': 4,\n",
    "    }}, {\n",
    "    'col':'electrical',\n",
    "    'mapping': {\n",
    "        'Mix': 0,\n",
    "        'FuseP': 1,\n",
    "        'FuseF': 2,\n",
    "        'FuseA': 3,\n",
    "        'SBrkr': 4\n",
    "    }}, {\n",
    "    'col': 'kitchen_qual',\n",
    "    'mapping': {\n",
    "        'Ex': 4,\n",
    "        'Gd': 3, \n",
    "        'TA': 2,\n",
    "        'Fa': 1,\n",
    "        'Po': 0,\n",
    "        'NA': -1,\n",
    "    }}, {   \n",
    "    'col': 'fireplace_qu',\n",
    "    'mapping': {\n",
    "        'Ex': 4,\n",
    "        'Gd': 3, \n",
    "        'TA': 2,\n",
    "        'Fa': 1,\n",
    "        'Po': 0,\n",
    "        'NA': -1,\n",
    "    }}, {\n",
    "    'col':'garage_finish',\n",
    "    'mapping': {\n",
    "        'Fin': 2,\n",
    "        'RFn': 1,\n",
    "        'Unf': 0,\n",
    "        'NA': -1,\n",
    "    }}, {\n",
    "    'col': 'garage_cond',\n",
    "    'mapping': {\n",
    "        'Ex': 4,\n",
    "        'Gd': 3, \n",
    "        'TA': 2,\n",
    "        'Fa': 1,\n",
    "        'Po': 0,\n",
    "        'NA': -1,\n",
    "    }}, {\n",
    "    'col': 'overall_cond',\n",
    "    'mapping':{\n",
    "        1: 0,\n",
    "        2: 1,\n",
    "        3: 2,\n",
    "        4: 3,\n",
    "        5: 4,\n",
    "        6: 5,\n",
    "        7: 6,\n",
    "        8: 7,\n",
    "        9: 8,\n",
    "    }}, {\n",
    "    'col': 'overall_qual',\n",
    "    'mapping':{\n",
    "        1: 0,\n",
    "        2: 1,\n",
    "        3: 2,\n",
    "        4: 3,\n",
    "        5: 4,\n",
    "        6: 5,\n",
    "        7: 6,\n",
    "        8: 7,\n",
    "        9: 8,\n",
    "    }},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c24cc3-96a2-46c4-aed9-e993d57068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.OrdinalEncoder(mapping = ordinal_cols_mapping, \n",
    "                             return_df = True)\n",
    "\n",
    "train_ordinal = train[feature_cat.get('ordinal_feat')]\n",
    "train_oe = encoder.fit_transform(train_ordinal)\n",
    "\n",
    "# Join df back to main train dataframe, drop original nominal feature columns\n",
    "train = train.drop(columns=feature_cat.get('ordinal_feat')).join(train_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7c6e5-8940-44a9-9c8b-acff7901e179",
   "metadata": {},
   "source": [
    "After studying the data dictionary, we mapped the ranked values to their respective integer value. We have encoded the respectively values in the ordinal features using `OrdinalEncoder` as it would maintain the importance of the ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa7c12-ca11-467c-9a45-c35bffc7036c",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3f148-a122-47bf-bd1c-7f607eaf438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of train set for preprocessing\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19298fd9-67f0-401e-95ec-e1d908a7e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore') \n",
    "# Ignore unknown variables when transforming validation/test set\n",
    "# Avoid dropping first, might drop cols differently for train/test sets leading to loss of data\n",
    "\n",
    "# Fit to train set & transform\n",
    "train_nominal = train[feature_cat.get('nominal_feat')]\n",
    "train_ohe = ohe.fit_transform(train_nominal)\n",
    "\n",
    "# Create a df with one hot encoded features\n",
    "train_ohe_df = pd.DataFrame(train_ohe.toarray(), columns=ohe.get_feature_names_out())\n",
    "\n",
    "# Join df back to main train dataframe, drop original nominal feature columns\n",
    "train = train.join(train_ohe_df).drop(columns=feature_cat.get('nominal_feat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df176379-fccc-4f6d-9b19-d820577aa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e224423-a4e3-4832-a6a1-663d1662a7bd",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606eb19a-d660-4b39-b6c9-c0bcdf3a0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cat.get('continuous_feat').remove('saleprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9275f77-f3cd-454d-875c-cf8acf54831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit to train set & transform\n",
    "scale_cols = feature_cat.get('continuous_feat') + feature_cat.get('ordinal_feat')\n",
    "train_scale = train[scale_cols]\n",
    "train_ss = ss.fit_transform(train_scale)\n",
    "\n",
    "# Create a df with scaled features\n",
    "train_ss_df = pd.DataFrame(train_ss, columns=scale_cols)\n",
    "\n",
    "# Join df back to main train dataframe, drop original feature columns\n",
    "train = train.drop(columns=scale_cols).join(train_ss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8a3d0-87ac-45e0-8c46-2b1269e8c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59894f49-3cf7-4503-8057-7f1b77cc0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a3b29-ebf4-47ac-92d1-491516ed8917",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Validation and Test Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50978dab-63c8-4350-b055-957272a3364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('./datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e940f0d-60e1-44b6-b227-1d2b5e67f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff42f53-e705-4133-9070-ee5964f41813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning column names \n",
    "test.rename(columns=lambda x: x.lower().replace(' ', '_').replace('/', '_'), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3effc-9a44-41ca-8ce1-91b9645930ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['yr_sold'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34c490-5e20-40f6-921c-8b90c17fb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making function to mirror the imputes of missing data in train data\n",
    "def impute_missing(df):\n",
    "     #imputing missing in garage_yr_built              \n",
    "    df.loc[df['garage_yr_blt'].isnull(), ['garage_yr_blt']] = df.loc[df['garage_yr_blt'].isnull(), 'year_built']\n",
    "        \n",
    "    #combining features to create new features\n",
    "    df['property_age'] = df['yr_sold'] - df['year_built']\n",
    "    df['garage_age'] = df['yr_sold'] - df['garage_yr_blt']\n",
    "    df['age_remod_add'] =df['year_remod_add'] - df['year_built']\n",
    "    \n",
    "    #changing 'bsmtfin_type_2' and 'bsmt_exposure' to mode\n",
    "    change_values(df,['bsmtfin_type_2'], 'Unf', 0)\n",
    "\n",
    "    change_values(df,['bsmt_exposure'], 'No', 0)\n",
    "\n",
    "    #changing balance basement features to appropriate values\n",
    "    change_values(df, bsmt_list, 'NA', 0.0)\n",
    "    \n",
    "    float_list2 = df.select_dtypes(include=['float64']).isnull().columns.tolist()\n",
    "    obj_list2 = df.select_dtypes(include=['object']).isnull().columns.tolist()\n",
    "\n",
    "    df[obj_list2]=df[obj_list2].fillna('NA')\n",
    "    df[float_list2]=df[float_list2].fillna(value=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33e1f6-c949-4279-8fbd-efe229ce8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making function to mirror the imputes of new features in train data\n",
    "def impute_new_features(df):\n",
    "    df['1st_flr_sf_total_bsmt_sf'] = df['1st_flr_sf'] * df['total_bsmt_sf']\n",
    "    df['bsmtfin_sf_1_total_bsmt_sf'] = df['bsmtfin_sf_1'] * df['total_bsmt_sf']\n",
    "    df['gr_liv_area_2nd_flr_sf'] = df['gr_liv_area'] * df['2nd_flr_sf']\n",
    "    df['gr_liv_area_1st_flr_sf'] = df['gr_liv_area'] * df['1st_flr_sf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5df495-60c1-4021-b058-ba99b5b543d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning test dataset\n",
    "impute_missing(test)\n",
    "\n",
    "impute_new_features(test)\n",
    "\n",
    "test=test[feature_cat.get('nominal_feat')+feature_cat.get('discrete_feat')+feature_cat.get('ordinal_feat')+feature_cat.get('continuous_feat')]\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a121b05-6174-4f16-a73e-23f9f65ab583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ordinal = test[feature_cat.get('ordinal_feat')]\n",
    "test_oe = encoder.fit_transform(test_ordinal)\n",
    "test = test.drop(columns=feature_cat.get('ordinal_feat')).join(test_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9efe1-c879-4cbf-9db1-2f269aeb66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nominal = test[feature_cat.get('nominal_feat')]\n",
    "test_ohe = ohe.fit_transform(test_nominal)\n",
    "test_ohe_df = pd.DataFrame(test_ohe.toarray(), columns=ohe.get_feature_names_out())\n",
    "test = test.join(test_ohe_df).drop(columns=feature_cat.get('nominal_feat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ecf68-7522-4471-8077-446261b2103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace=True)\n",
    "scale_cols = feature_cat.get('continuous_feat')+feature_cat.get('ordinal_feat')\n",
    "scaled = test[scale_cols]\n",
    "scaled_ss = ss.transform(scaled)\n",
    "scaled_ss_df = pd.DataFrame(scaled_ss, columns=scale_cols)\n",
    "test =test.drop(columns=scale_cols).join(scaled_ss_df)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83155a47-8753-4179-951a-53c404d9d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50374229-8ea2-4cb8-80e5-7e5ab0d3b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e60a9-f716-4e9c-8a18-71f11ef807af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning valid dataset\n",
    "impute_missing(valid)\n",
    "\n",
    "impute_new_features(valid)\n",
    "\n",
    "#must add saleprice column as it was dropped earlier on \n",
    "valid=valid[feature_cat.get('nominal_feat')+feature_cat.get('discrete_feat')+feature_cat.get('ordinal_feat')+feature_cat.get('continuous_feat')+['saleprice']]\n",
    "valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d747e5a8-3a0d-4776-831e-18f531e5d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ordinal = valid[feature_cat.get('ordinal_feat')]\n",
    "valid_oe = encoder.fit_transform(valid_ordinal)\n",
    "valid = valid.drop(columns=feature_cat.get('ordinal_feat')).join(valid_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de638668-706b-44fe-b8fe-f7baf45ccd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_nominal = valid[feature_cat.get('nominal_feat')]\n",
    "valid_ohe = ohe.fit_transform(valid_nominal)\n",
    "valid_ohe_df = pd.DataFrame(valid_ohe.toarray(), columns=ohe.get_feature_names_out())\n",
    "valid = valid.join(valid_ohe_df).drop(columns=feature_cat.get('nominal_feat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f6f86-00b6-49bf-946c-534d4b453b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.reset_index(drop=True, inplace=True)\n",
    "scale_cols = feature_cat.get('continuous_feat')+feature_cat.get('ordinal_feat')\n",
    "scaled = valid[scale_cols]\n",
    "scaled_ss = ss.transform(scaled)\n",
    "scaled_ss_df = pd.DataFrame(scaled_ss, columns=scale_cols)\n",
    "valid =valid.drop(columns=scale_cols).join(scaled_ss_df)\n",
    "valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0e742-bdc9-4165-9ca7-b4c565fb97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid.shape)\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b7527-d871-4d31-8e8a-3ec61a5334c0",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Shape Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de803e5-d01e-47f4-8cdc-69a3930c88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_cols(first_df, second_df):\n",
    "    missing=[]\n",
    "    for cols in first_df.columns.values.tolist():\n",
    "        if cols not in second_df.columns.values.tolist():\n",
    "            missing.append(cols)\n",
    "\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c68f2-bd87-4bae-86b5-d779c97438f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing columns in valid dataset with train dataset\n",
    "check_missing_cols(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789c4d9-b058-4c2f-b1b3-06268da2b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing columns in test dataset with train dataset\n",
    "check_missing_cols(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566522a-bca6-43e3-8e7a-46e6c5bf1515",
   "metadata": {},
   "source": [
    "Before we can train and test our models with these datasets, we have to make sure the number of columns are the same. Due to different values in the columns, some values may not appear in the test/valid dataset that may appear in the training set. Thus, when we do the necessary encoding, some of the values will not be reflected and leading to the uneven number of columns.\n",
    "For the train and valid dataset, we can impute the missing columns with all values being 0 in the column.\n",
    "Same for the test set, but we remove then `'saleprice'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c925b7-7978-434e-b3f8-8686498fbaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_valid = valid.reindex(columns = train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6f773-7db3-46f4-ab15-107954a7d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test= test.reindex(columns = train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586307c-fec5-4e27-8e52-98b06240eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.drop(columns='saleprice', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f57da-a1af-47f1-b354-287142e2a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final check\n",
    "print(f'Number of columns in train is {len(train.columns.values.tolist())}')\n",
    "print(f'Number of columns in valid is {len(final_valid.columns.values.tolist())}')\n",
    "print(f'Number of columns in test is {len(final_test.columns.values.tolist())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662f69d-71ac-40d1-9362-48e8258abdc2",
   "metadata": {},
   "source": [
    "Finally, we have the same number of columns after cleaning and pre-processing the various dataset. Take note that train and valid dataset has the column `'saleprice'`, which will be dropped before the modelling stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea3f69-924e-4063-ab17-d8541af3007f",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4f5b8-3a3c-4ef4-933d-a4d65b4ff550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting cleaned datasets to .csv files\n",
    "train.to_csv('./datasets/training_model.csv', index=False)\n",
    "final_valid.to_csv('./datasets/validation_model.csv', index=False)\n",
    "final_test.to_csv('./datasets/test_kaggle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
